{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOc/54OwOinhEG0f6GKit97"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"25G2cZtLqs8V","executionInfo":{"status":"ok","timestamp":1751260598181,"user_tz":-330,"elapsed":11354,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","source":["input_embeddings = torch.tensor([\n","    [0.43, 0.15, 0.89], #x1\n","    [0.55, 0.87, 0.66], #x2\n","    [0.57, 0.85, 0.64], #x3\n","    [0.22, 0.58, 0.33], #x4\n","    [0.77, 0.25, 0.10], #x5\n","    [0.05, 0.80, 0.55]  #x6\n","])"],"metadata":{"id":"rgQcD5Onq7Gj","executionInfo":{"status":"ok","timestamp":1751260598233,"user_tz":-330,"elapsed":45,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## **Self-Attention without trainable weights**"],"metadata":{"id":"C-rTbo79bNMM"}},{"cell_type":"markdown","source":["### Lets first apply self-attention to single input embedding (x2)"],"metadata":{"id":"GKXKwna1r141"}},{"cell_type":"code","source":["query = input_embeddings[1]\n","query"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"amChvjkLr1K-","executionInfo":{"status":"ok","timestamp":1751260598349,"user_tz":-330,"elapsed":103,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"f002fb35-2144-4e4e-b5f1-54549ea557be"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.5500, 0.8700, 0.6600])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["attention_scores = torch.empty(input_embeddings.shape[0])\n","\n","for i, input in enumerate(input_embeddings):\n","  dot_product = torch.dot(input,query)\n","  attention_scores[i] = dot_product\n","\n","print(attention_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTd2jsxYwnQV","executionInfo":{"status":"ok","timestamp":1751260598390,"user_tz":-330,"elapsed":40,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"068e7be3-e092-4e7a-b70e-b8a71f3f55c8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"]}]},{"cell_type":"code","source":["#Alternative way\n","input_embeddings @ query.T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHktgkHJwnSI","executionInfo":{"status":"ok","timestamp":1751260598462,"user_tz":-330,"elapsed":68,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"c079ef38-42da-405a-d860-96f9a40f72d2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-5-4061235695.py:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3725.)\n","  input_embeddings @ query.T\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#noramlize attention scores for interpretability  and stable training which will be used attention weights\n","attention_weights = torch.softmax(attention_scores, dim=-1)\n","attention_weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEzVl4FSwnVn","executionInfo":{"status":"ok","timestamp":1751260598542,"user_tz":-330,"elapsed":83,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"3ccb3195-4dde-4f16-d51a-26a34b8453c1"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#next we will use these attention weights for generating context vector z2 for the x2 in the input sequence\n","context_vector_z2 = attention_weights @ input_embeddings\n","context_vector_z2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"po09sgbO0o5r","executionInfo":{"status":"ok","timestamp":1751260598584,"user_tz":-330,"elapsed":44,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"cb8936cd-2eaf-42f9-9ac6-b7af5aecc98b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.4419, 0.6515, 0.5683])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["################################\n","############## OR ##############\n","################################\n","context_vector_z2 = torch.zeros(query.shape)\n","for i, input in enumerate(input_embeddings):\n","  context_vector_z2 += input * attention_weights[i]\n","\n","context_vector_z2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"559F93qZ26Uu","executionInfo":{"status":"ok","timestamp":1751260598613,"user_tz":-330,"elapsed":30,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"3005bc4a-52e4-445f-9791-832267325135"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.4419, 0.6515, 0.5683])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### Self-attention to all elements in the input sequence"],"metadata":{"id":"lGYKnCoQ24wd"}},{"cell_type":"code","source":["attention_scores_all = input_embeddings @ input_embeddings.T\n","\n","attention_scores_all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AP3wUlf42lk","executionInfo":{"status":"ok","timestamp":1751260598714,"user_tz":-330,"elapsed":82,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"0d648816-64ac-4b5f-9e2a-041ea09d8f21"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n","        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n","        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n","        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n","        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n","        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["attention_weights_all = torch.softmax(attention_scores_all, dim=-1)\n","\n","attention_weights_all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1FZh-aHR42nh","executionInfo":{"status":"ok","timestamp":1751260598715,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"05cc7366-740f-4311-9d99-f942d88d91f7"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n","        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n","        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n","        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n","        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n","        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#comparing individual and batch attention weights for x2 element\n","print('Attention weights for x2 (individual calculation): ', attention_weights)\n","print('Attention weights for x2 (batch calculation): ', attention_weights_all[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dgxE03X54U-","executionInfo":{"status":"ok","timestamp":1751260598726,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"6bfe6180-3bca-429d-8a77-9a39f1e068e2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention weights for x2 (individual calculation):  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n","Attention weights for x2 (batch calculation):  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n"]}]},{"cell_type":"markdown","source":["As can be seen that both the attention weight tensors for x2 are same"],"metadata":{"id":"8onNMfOY50wm"}},{"cell_type":"code","source":["#computing the context vectors for all the elements in the input sequence\n","context_vectors_all = attention_weights_all @ input_embeddings\n","context_vectors_all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubIaBEFQ42q5","executionInfo":{"status":"ok","timestamp":1751260598748,"user_tz":-330,"elapsed":25,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"e65f36f6-9b38-4dc3-e500-03537c1aea6d"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4421, 0.5931, 0.5790],\n","        [0.4419, 0.6515, 0.5683],\n","        [0.4431, 0.6496, 0.5671],\n","        [0.4304, 0.6298, 0.5510],\n","        [0.4671, 0.5910, 0.5266],\n","        [0.4177, 0.6503, 0.5645]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["print(\"Context vector z2 (individual calculation): \", context_vector_z2)\n","print(\"Context vector z2 (batch calculation): \", context_vectors_all[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uHvLFJ9payOq","executionInfo":{"status":"ok","timestamp":1751260598825,"user_tz":-330,"elapsed":76,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"56e650e7-9397-4058-f751-3d0f96fc5c72"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Context vector z2 (individual calculation):  tensor([0.4419, 0.6515, 0.5683])\n","Context vector z2 (batch calculation):  tensor([0.4419, 0.6515, 0.5683])\n"]}]},{"cell_type":"markdown","source":["## **Self-Attention with trainable weights**"],"metadata":{"id":"OaSmU4rDbSIE"}},{"cell_type":"markdown","source":["### For single input element x2"],"metadata":{"id":"UgN9UWTAIoDA"}},{"cell_type":"code","source":["#lets create weights matrix for query, key and value\n","x2 = input_embeddings[1]\n","dim_in = input_embeddings.shape[-1]\n","dim_out = 2\n","\n","torch.manual_seed(123)\n","w_query = torch.nn.Parameter(torch.rand(dim_in,dim_out), requires_grad=False)\n","w_keys = torch.nn.Parameter(torch.rand(dim_in,dim_out), requires_grad=False)\n","w_values = torch.nn.Parameter(torch.rand(dim_in,dim_out), requires_grad=False)"],"metadata":{"id":"zCYwbA8iJX1b","executionInfo":{"status":"ok","timestamp":1751260598827,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["query = x2 @ w_query\n","keys = input_embeddings @ w_keys\n","values = input_embeddings @ w_values\n","\n","query"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZGmdFcKXdtD","executionInfo":{"status":"ok","timestamp":1751260598868,"user_tz":-330,"elapsed":38,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"baf1758a-afdf-405e-d16a-c77bf5b5cc05"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.4306, 1.4551])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["attention_scores = query @ keys.T\n","attention_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KcTXPpOsa1Ts","executionInfo":{"status":"ok","timestamp":1751260598884,"user_tz":-330,"elapsed":34,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"90f3e9cc-11eb-4c38-eb4d-faf45497f157"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#lets scale the attention scores using softmax but before that we will scale the dot-products (or attention scores) by dividing it by square root of key vector's dimension size\n","attention_weights = torch.softmax((attention_scores/keys.shape[-1] ** 0.5), dim=-1)\n","attention_weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSSFmO11bhe5","executionInfo":{"status":"ok","timestamp":1751260598914,"user_tz":-330,"elapsed":30,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"58f95f03-1740-4e8f-8a42-e8a26632c618"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["#lets calculate the context vector for x2\n","context_vector_z2 = attention_weights @ values\n","context_vector_z2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xby7MpVDiocA","executionInfo":{"status":"ok","timestamp":1751260598959,"user_tz":-330,"elapsed":43,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"c54ac1f8-b219-41f1-cfef-9542143649ca"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.3061, 0.8210])"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["### Lets generalize this approach through class implementation"],"metadata":{"id":"T00X9XJFdF3f"}},{"cell_type":"code","source":["class SelfAttention_v1(torch.nn.Module):\n","  def __init__(self, dim_in, dim_out):\n","    super().__init__()\n","    self.w_query = torch.nn.Parameter(torch.rand(dim_in, dim_out))\n","    self.w_key = torch.nn.Parameter(torch.rand(dim_in, dim_out))\n","    self.w_value = torch.nn.Parameter(torch.rand(dim_in, dim_out))\n","\n","  def forward(self, inputs):\n","    queries = inputs @ self.w_query\n","    keys = inputs @ self.w_key\n","    values = inputs @ self.w_value\n","    attention_scores_all = queries @ keys.T\n","    attention_weights_all = torch.softmax(attention_scores_all/keys.shape[-1] ** 0.5, dim=-1)\n","    context_vectors_all = attention_weights_all @ values\n","\n","    return context_vectors_all"],"metadata":{"id":"mDbhqNnvdRzv","executionInfo":{"status":"ok","timestamp":1751260598960,"user_tz":-330,"elapsed":26,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","sa_v1 = SelfAttention_v1(dim_in, dim_out)\n","print(sa_v1(input_embeddings))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTqbEBytnPSy","executionInfo":{"status":"ok","timestamp":1751260598967,"user_tz":-330,"elapsed":29,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"14fbca3e-894f-4aa0-efa6-56ecdd8f50d2"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2996, 0.8053],\n","        [0.3061, 0.8210],\n","        [0.3058, 0.8203],\n","        [0.2948, 0.7939],\n","        [0.2927, 0.7891],\n","        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"]}]},{"cell_type":"markdown","source":["Lets use Linear layer for weight matrix initialization and matrix multiplication"],"metadata":{"id":"KZ30YZCFAmNo"}},{"cell_type":"code","source":["class SelfAttention_v2(torch.nn.Module):\n","  def __init__(self, dim_in, dim_out, qkv_bias=False):\n","    super().__init__()\n","    self.w_query = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.w_key = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.w_value = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","\n","  def forward(self, inputs):\n","    queries = self.w_query(inputs)\n","    keys = self.w_key(inputs)\n","    values = self.w_value(inputs)\n","    attention_scores_all = queries @ keys.T\n","    attention_weights_all = torch.softmax(attention_scores_all/keys.shape[-1] ** 0.5, dim=-1)\n","    context_vectors_all = attention_weights_all @ values\n","\n","    return context_vectors_all"],"metadata":{"id":"kCEUBSJyBB2b","executionInfo":{"status":"ok","timestamp":1751260599014,"user_tz":-330,"elapsed":46,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["sa_v2 = SelfAttention_v2(dim_in, dim_out)\n","print(sa_v2(input_embeddings))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QstufmlHIhte","executionInfo":{"status":"ok","timestamp":1751260599054,"user_tz":-330,"elapsed":38,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"a87bc8ca-3462-44f8-f2f4-eb40fab7bc7d"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5085, 0.3508],\n","        [0.5084, 0.3508],\n","        [0.5084, 0.3506],\n","        [0.5074, 0.3471],\n","        [0.5076, 0.3446],\n","        [0.5077, 0.3493]], grad_fn=<MmBackward0>)\n"]}]},{"cell_type":"markdown","source":["Both the classes results different context vectors because of different weight parameter initialization"],"metadata":{"id":"EUiJBOcxI0ME"}},{"cell_type":"markdown","source":["Lets use the weights of Linear layers in SelfAttention_v1"],"metadata":{"id":"ypHImYU7JYW7"}},{"cell_type":"code","source":["sa_v1.w_query = torch.nn.Parameter(sa_v2.w_query.weight.T) #transposing the weight matrix to match the original shape since Linear layer uses weight matrix which is transposed\n","sa_v1.w_key = torch.nn.Parameter(sa_v2.w_key.weight.T)\n","sa_v1.w_value = torch.nn.Parameter(sa_v2.w_value.weight.T)\n","\n","print(sa_v1(input_embeddings))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTPkjnZ_KoIB","executionInfo":{"status":"ok","timestamp":1751260599093,"user_tz":-330,"elapsed":36,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"57cf7a89-0e43-4279-b166-131a8c687258"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5085, 0.3508],\n","        [0.5084, 0.3508],\n","        [0.5084, 0.3506],\n","        [0.5074, 0.3471],\n","        [0.5076, 0.3446],\n","        [0.5077, 0.3493]], grad_fn=<MmBackward0>)\n"]}]},{"cell_type":"markdown","source":["## **Causal Attention**"],"metadata":{"id":"A-NKERWy-Tz4"}},{"cell_type":"code","source":["context_length = input_embeddings.shape[0]\n","context_length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m90CqUGw_TyJ","executionInfo":{"status":"ok","timestamp":1751260599094,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"a688ecca-ea93-4da3-bc20-72ecbf865e6a"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["#lets create a mask\n","mask = torch.triu(torch.ones(context_length,context_length), diagonal=1)\n","mask"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4iRHi9__ZfD","executionInfo":{"status":"ok","timestamp":1751260599135,"user_tz":-330,"elapsed":25,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"b07b61c8-0578-43f4-fd7e-7b492dd20b67"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 1., 1., 1., 1., 1.],\n","        [0., 0., 1., 1., 1., 1.],\n","        [0., 0., 0., 1., 1., 1.],\n","        [0., 0., 0., 0., 1., 1.],\n","        [0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["masked_attention_scores_all = attention_scores_all.masked_fill(mask.bool(), -torch.inf)\n","masked_attention_scores_all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_NRf_c1Bha_","executionInfo":{"status":"ok","timestamp":1751260599163,"user_tz":-330,"elapsed":11,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"8a919e29-eb73-444c-ff4f-8f10e7231760"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.9995,   -inf,   -inf,   -inf,   -inf,   -inf],\n","        [0.9544, 1.4950,   -inf,   -inf,   -inf,   -inf],\n","        [0.9422, 1.4754, 1.4570,   -inf,   -inf,   -inf],\n","        [0.4753, 0.8434, 0.8296, 0.4937,   -inf,   -inf],\n","        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654,   -inf],\n","        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["masked_attention_weights_all = torch.softmax(masked_attention_scores_all/input_embeddings.shape[-1]**0.5, dim=-1)\n","masked_attention_weights_all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvsJIIDTIXU2","executionInfo":{"status":"ok","timestamp":1751260599198,"user_tz":-330,"elapsed":32,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"315aae5e-3127-4bd0-99f0-1d6bfc338e85"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.4226, 0.5774, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2698, 0.3670, 0.3632, 0.0000, 0.0000, 0.0000],\n","        [0.2235, 0.2764, 0.2742, 0.2259, 0.0000, 0.0000],\n","        [0.1858, 0.2146, 0.2157, 0.1744, 0.2095, 0.0000],\n","        [0.1511, 0.1965, 0.1936, 0.1533, 0.1243, 0.1811]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["torch.manual_seed(123)\n","dropout = torch.nn.Dropout(0.5)\n","dropout(masked_attention_weights_all)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUq2plVsMUyM","executionInfo":{"status":"ok","timestamp":1751260599273,"user_tz":-330,"elapsed":78,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"1284721c-a84e-446f-cf1d-9f9a732d528e"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 1.1548, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.7263, 0.0000, 0.0000, 0.0000],\n","        [0.4470, 0.5528, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.3931, 0.0000, 0.0000, 0.0000, 0.0000]])"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["### Compact class implementation for batch processing"],"metadata":{"id":"YjgIMNjnOdhs"}},{"cell_type":"code","source":["batch_inp = torch.stack((input_embeddings, input_embeddings), dim=0)\n","batch_inp.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xG4M8KXWmKEx","executionInfo":{"status":"ok","timestamp":1751260599276,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"9633b800-5a58-48e3-e7dc-d13636143cd6"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 6, 3])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["class CausalAttention(torch.nn.Module):\n","  def __init__(self, dim_in, dim_out, context_length, dropout, qkv_bias=False):\n","    super().__init__()\n","    self.w_query = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.w_key = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.w_value = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.dropout = torch.nn.Dropout(dropout)\n","    self.register_buffer(\n","        'mask',\n","        torch.triu(torch.ones(context_length, context_length), diagonal=1)\n","    )\n","\n","  def forward(self, x):\n","    batch_size, num_tokens, dim_in = x.shape\n","    queries = self.w_query(x)\n","    keys = self.w_key(x)\n","    values = self.w_value(x)\n","\n","    attention_scores = queries @ keys.transpose(1,2)\n","    attention_weights = torch.softmax(\n","        attention_scores.masked_fill_(self.mask.bool()[:num_tokens,:num_tokens], -torch.inf)/keys.shape[-1]**0.5,\n","        dim=-1\n","    )\n","    attention_weights = self.dropout(attention_weights)\n","\n","    context_vectors = attention_weights @ values\n","\n","    return context_vectors"],"metadata":{"id":"aNlY0zxCoqCa","executionInfo":{"status":"ok","timestamp":1751260599297,"user_tz":-330,"elapsed":23,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","context_length = batch_inp.shape[1]\n","ca = CausalAttention(3,2,context_length,0.5)\n","print(ca(batch_inp))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-WEJ7qHzBOv","executionInfo":{"status":"ok","timestamp":1751260599330,"user_tz":-330,"elapsed":36,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"ec08d0ce-02b7-4e9a-a07e-df4d8f206d51"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.0000,  0.0000],\n","         [-0.4368,  0.2142],\n","         [-0.7751,  0.0077],\n","         [-0.9140, -0.2769],\n","         [ 0.0000,  0.0000],\n","         [-0.6906, -0.0974]],\n","\n","        [[-0.9038,  0.4432],\n","         [ 0.0000,  0.0000],\n","         [-0.2883,  0.1414],\n","         [-0.9140, -0.2769],\n","         [-0.4416, -0.1410],\n","         [-0.5272, -0.1706]]], grad_fn=<UnsafeViewBackward0>)\n"]}]},{"cell_type":"markdown","source":["## **Multi-head Attention**"],"metadata":{"id":"fnjZFGef2Qvu"}},{"cell_type":"markdown","source":["### Multi-head wrapper around CausalAttention class"],"metadata":{"id":"BwwrnV4a2kz3"}},{"cell_type":"code","source":["class MultiHeadWrapper(torch.nn.Module):\n","  def __init__(self, dim_in, dim_out, context_length, num_heads, dropout, qkv_bias=False):\n","    super().__init__()\n","    self.heads = torch.nn.ModuleList([\n","        CausalAttention(dim_in, dim_out, context_length, dropout, qkv_bias)\n","        for _ in range(num_heads)\n","    ])\n","\n","  def forward(self, x):\n","    return torch.cat([head(x) for head in self.heads], dim=-1)"],"metadata":{"id":"hY-lErze2h5U","executionInfo":{"status":"ok","timestamp":1751260599363,"user_tz":-330,"elapsed":35,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","ma_wrapper = MultiHeadWrapper(3, 1, 6, 2, 0)\n","context_vectors = ma_wrapper(batch_inp)\n","\n","print(context_vectors.shape)\n","print(context_vectors)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGSluL94DzpT","executionInfo":{"status":"ok","timestamp":1751260599384,"user_tz":-330,"elapsed":33,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"b9ffb135-5246-4ead-9817-5de12621984b"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 6, 2])\n","tensor([[[-0.5740,  0.2216],\n","         [-0.7320,  0.0155],\n","         [-0.7774, -0.0546],\n","         [-0.6979, -0.0817],\n","         [-0.6538, -0.0957],\n","         [-0.6424, -0.1065]],\n","\n","        [[-0.5740,  0.2216],\n","         [-0.7320,  0.0155],\n","         [-0.7774, -0.0546],\n","         [-0.6979, -0.0817],\n","         [-0.6538, -0.0957],\n","         [-0.6424, -0.1065]]], grad_fn=<CatBackward0>)\n"]}]},{"cell_type":"markdown","source":["Here, the problem is that we are implementing multihead attention sequentially (not efficient)"],"metadata":{"id":"h696Iuw6FUWO"}},{"cell_type":"markdown","source":["### Parallel Multi-head Attention"],"metadata":{"id":"S1LVknlrGHFT"}},{"cell_type":"code","source":["class MultiHeadAttention(torch.nn.Module):\n","  def __init__(self, dim_in, dim_out, context_length, dropout, num_heads, qkv_bias=False):\n","    super().__init__()\n","    assert (dim_out % num_heads == 0), \"dim_out must be divisible by num_heads\"\n","\n","    self.dim_out = dim_out # final merged context vector embedding size\n","    self.num_heads = num_heads\n","    self.head_dim = dim_out//num_heads # embedding size of context vector in single head\n","    self.w_query = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.w_key = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.w_value = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.out_proj = torch.nn.Linear(dim_out, dim_out) # transform merged context_vectors into similar dimension size vectors\n","    self.dropout = torch.nn.Dropout(dropout)\n","    self.register_buffer(\n","        'mask',\n","        torch.triu(torch.ones(context_length, context_length), diagonal=1)\n","    )\n","\n","  def forward(self, x):\n","    batch_size, num_tokens, dim_in = x.shape\n","    queries = self.w_query(x)\n","    keys = self.w_key(x)\n","    values = self.w_value(x)  #shape (batch_size, num_tokens, dim_out)\n","\n","    queries = queries.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n","    keys = keys.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n","    values = values.view(batch_size, num_tokens, self.num_heads, self.head_dim) #shape (batch_size, num_tokens, num_heads, head_dim)\n","\n","    queries = queries.transpose(1,2)\n","    keys = keys.transpose(1,2)\n","    values = values.transpose(1,2) #shape (batch_size, num_heads, num_tokens, head_dim)\n","\n","    attention_scores = queries @ keys.transpose(2,3)\n","    attention_scores.masked_fill_(self.mask.bool()[:num_tokens,:num_tokens], -torch.inf)\n","\n","    attention_weights = torch.softmax(attention_scores/keys.shape[-1]**0.5, dim=-1)\n","    attention_weights = self.dropout(attention_weights)\n","\n","    context_vectors = (attention_weights @ values).transpose(1,2) #transposing axis 1,2  since we have to merge the context vectors by num_heads and head_dim, so required shape will now be (batch_size, num_tokens, num_heads, head_dim)\n","    context_vectors = context_vectors.contiguous().view(batch_size, num_tokens, self.dim_out)\n","\n","    context_vectors = self.out_proj(context_vectors)\n","\n","    return context_vectors"],"metadata":{"id":"-yjCL5RtGLoG","executionInfo":{"status":"ok","timestamp":1751260599447,"user_tz":-330,"elapsed":65,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","batch_size, context_length, dim_in = batch_inp.shape\n","dim_out = 2\n","mha = MultiHeadAttention(dim_in, dim_out, context_length, 0, num_heads=2)\n","context_vectors = mha(batch_inp)\n","print(context_vectors.shape)\n","print(context_vectors)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IDSTDpShqmFy","executionInfo":{"status":"ok","timestamp":1751260599466,"user_tz":-330,"elapsed":46,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"e38c2e6c-ba7d-4643-befb-48e56b0fa3e6"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 6, 2])\n","tensor([[[0.3190, 0.4858],\n","         [0.2943, 0.3897],\n","         [0.2856, 0.3593],\n","         [0.2693, 0.3873],\n","         [0.2639, 0.3928],\n","         [0.2575, 0.4028]],\n","\n","        [[0.3190, 0.4858],\n","         [0.2943, 0.3897],\n","         [0.2856, 0.3593],\n","         [0.2693, 0.3873],\n","         [0.2639, 0.3928],\n","         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n"]}]},{"cell_type":"code","source":["# initializing GPT-2 size attention module\n","dim_in = 768\n","dim_out = 768\n","context_length = 1024\n","\n","gpt_batch_inp = torch.rand(2,context_length, dim_in)\n","\n","mha2 = MultiHeadAttention(dim_in, dim_out, context_length, 0.1, 12)\n","context_vectors = mha2(gpt_batch_inp)\n","print(context_vectors.shape)\n","print(context_vectors)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E--PE_XPQ1X9","executionInfo":{"status":"ok","timestamp":1751260897366,"user_tz":-330,"elapsed":994,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"00f4c420-04d3-4b42-de8d-8ef5883fe44e"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1024, 768])\n","tensor([[[ 0.0170,  0.1816, -0.2170,  ...,  0.0639,  0.0964,  0.2717],\n","         [-0.0047,  0.0741, -0.1810,  ..., -0.0047,  0.2833,  0.2123],\n","         [ 0.0483,  0.0444, -0.1795,  ...,  0.0255,  0.2041,  0.1987],\n","         ...,\n","         [ 0.0416,  0.1521, -0.1774,  ...,  0.0179,  0.1017,  0.1228],\n","         [ 0.0436,  0.1570, -0.1777,  ...,  0.0166,  0.1021,  0.1215],\n","         [ 0.0483,  0.1519, -0.1812,  ...,  0.0172,  0.1026,  0.1172]],\n","\n","        [[ 0.1762,  0.0427, -0.3035,  ..., -0.1063,  0.1445,  0.1308],\n","         [-0.0762,  0.0785, -0.2634,  ...,  0.0014,  0.0424,  0.1250],\n","         [ 0.0960,  0.1276, -0.2463,  ..., -0.0068,  0.1109,  0.1335],\n","         ...,\n","         [ 0.0451,  0.1483, -0.1869,  ...,  0.0137,  0.0928,  0.1143],\n","         [ 0.0488,  0.1542, -0.1884,  ...,  0.0187,  0.0982,  0.1175],\n","         [ 0.0434,  0.1553, -0.1887,  ...,  0.0109,  0.0900,  0.1159]]],\n","       grad_fn=<ViewBackward0>)\n"]}]}]}