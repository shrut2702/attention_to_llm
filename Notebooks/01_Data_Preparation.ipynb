{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1CXoOP4XOLBkCeGIS2ZvYl2C3p3ptVSIc","authorship_tag":"ABX9TyMTRXsckvGn1Ekze4lAvXpk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Importing Text Data**"],"metadata":{"id":"KV3GINk3y9uW"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bMscGbHzykoH","executionInfo":{"status":"ok","timestamp":1750098471642,"user_tz":-330,"elapsed":2210,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"34db7bc5-18ea-44fc-b5a6-5830c5f3b22f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/LLM/Data/the-verdict.txt',\n"," <http.client.HTTPMessage at 0x79d7ef359c50>)"]},"metadata":{},"execution_count":2}],"source":["import urllib.request\n","url = (\"https://raw.githubusercontent.com/rasbt/\"\n","\"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n","\"the-verdict.txt\")\n","file_path = \"/content/drive/My Drive/LLM/Data/the-verdict.txt\"\n","urllib.request.urlretrieve(url, file_path)"]},{"cell_type":"code","source":["with open(file_path,\"r\",encoding=\"utf-8\") as f:\n","  raw_text = f.read()\n","\n","print(\"Total number of character: \", len(raw_text))\n","print(raw_text[:99])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WI5Kvf9X0sNa","executionInfo":{"status":"ok","timestamp":1750098471646,"user_tz":-330,"elapsed":39,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"45e77bd7-cc5f-41d6-b490-7cdb2d88ab86"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of character:  20479\n","I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"]}]},{"cell_type":"markdown","source":["### Tokenization"],"metadata":{"id":"M7jRFvydCWhZ"}},{"cell_type":"code","source":["import re"],"metadata":{"id":"XQ3qor9IBIq_","executionInfo":{"status":"ok","timestamp":1750098471647,"user_tz":-330,"elapsed":26,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n","preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","print(len(preprocessed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8M3-mfL0sRC","executionInfo":{"status":"ok","timestamp":1750098471649,"user_tz":-330,"elapsed":21,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"be1b92f5-98c0-4491-cc0a-50dc3f47bd6c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["4690\n"]}]},{"cell_type":"code","source":["print(preprocessed[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zHLyVgc0scF","executionInfo":{"status":"ok","timestamp":1750098471660,"user_tz":-330,"elapsed":20,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"a8748b32-9c11-4e73-edee-f839be132022"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was']\n"]}]},{"cell_type":"markdown","source":["### Assign token ids to tokens"],"metadata":{"id":"YYjhhWmPCaqp"}},{"cell_type":"code","source":["all_words = sorted(set(preprocessed))\n","all_words.extend(['<|endoftext|>','<|unk|>']) # endoftoken is added to the beginning of text or document to distinguish between independent documents\n","vocab_size = len(all_words)\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"si3ZQjunCVT4","executionInfo":{"status":"ok","timestamp":1750098471699,"user_tz":-330,"elapsed":36,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"29306eb2-3a5f-4bc5-9554-a95f641d6c3f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["1132\n"]}]},{"cell_type":"code","source":["vocab = {token:i for i,token in enumerate(all_words)}"],"metadata":{"id":"_Zk8s4bdC737","executionInfo":{"status":"ok","timestamp":1750098471733,"user_tz":-330,"elapsed":32,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(list(vocab.items())[-5:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ksa7dxVyTSxz","executionInfo":{"status":"ok","timestamp":1750098471741,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"50b110da-0d4b-4ae0-99f0-2b155e31d9ed"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[('younger', 1127), ('your', 1128), ('yourself', 1129), ('<|endoftext|>', 1130), ('<|unk|>', 1131)]\n"]}]},{"cell_type":"code","source":["class SimpleTokenizer:\n","  def __init__(self, vocab) -> None:\n","    self.token_to_id = vocab\n","    self.id_to_token = {v:k for k,v in vocab.items()} # for post processing the LLM output\n","\n","  def encode(self, text):\n","    split_text = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n","    split_text = [item.strip() for item in split_text if item.strip()]\n","    split_text = [word if word in self.token_to_id else '<|unk|>' for word in split_text ]\n","    ids = [self.token_to_id[t] for t in split_text]\n","    return ids\n","\n","  def decode(self, ids):\n","    tokens = [self.id_to_token[i] for i in ids]\n","    text = \" \".join(tokens)\n","    text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n","    return text"],"metadata":{"id":"quZfsrNrUUge","executionInfo":{"status":"ok","timestamp":1750098471745,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["tokenizer = SimpleTokenizer(vocab)\n","text = \"\"\"\n","A slight shade of constraint crossed Mrs. Gisburn's open countenance. \"It's his ridiculous modesty, you know. He says they're not fit to have about; he's sent them all away except one--my portrait--and that I have to keep upstairs.\"\n","\"\"\"\n","encoded_ids = tokenizer.encode(text)\n","print(encoded_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVfFyBSRUUju","executionInfo":{"status":"ok","timestamp":1750098471757,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"477ccbf5-fbf9-45bf-e056-08bb0c58a225"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[11, 901, 873, 722, 286, 301, 67, 7, 38, 2, 850, 733, 295, 7, 1, 56, 2, 850, 549, 842, 679, 5, 1126, 596, 7, 48, 858, 994, 2, 819, 711, 443, 1016, 530, 118, 9, 533, 2, 850, 869, 990, 145, 187, 405, 729, 6, 697, 782, 6, 157, 987, 53, 530, 1016, 591, 1055, 7, 1]\n"]}]},{"cell_type":"code","source":["decoded_text = tokenizer.decode(encoded_ids)\n","print(decoded_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBOOG-pWdkRU","executionInfo":{"status":"ok","timestamp":1750098471766,"user_tz":-330,"elapsed":10,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"b863028a-d7e7-4353-bc07-3efebb5f6f7d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["A slight shade of constraint crossed Mrs. Gisburn' s open countenance.\" It' s his ridiculous modesty, you know. He says they' re not fit to have about; he' s sent them all away except one -- my portrait -- and that I have to keep upstairs.\"\n"]}]},{"cell_type":"code","source":["unseen_text = \"Hello, I was checking out if there's any update.\" # lets test our tokenizer from text outside the training data\n","print(tokenizer.decode(tokenizer.encode(unseen_text)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7Kf6JjUejux","executionInfo":{"status":"ok","timestamp":1750098471799,"user_tz":-330,"elapsed":10,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"b4dfdbf9-9c47-406e-b5dc-bdc3c3aa0469"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["<|unk|>, I was <|unk|> out if there' s any <|unk|>.\n"]}]},{"cell_type":"markdown","source":["### Byte Pair Encoding (more sophisticated tokenizer)"],"metadata":{"id":"iMSZ9_SnNVNk"}},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzyFLByZNkHD","executionInfo":{"status":"ok","timestamp":1750098481632,"user_tz":-330,"elapsed":9832,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"949b96f8-0f56-46b6-a1f1-d289c674e9e1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"]}]},{"cell_type":"code","source":["import tiktoken"],"metadata":{"id":"gIbT1HvDNted","executionInfo":{"status":"ok","timestamp":1750098481854,"user_tz":-330,"elapsed":217,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(tiktoken.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1g2Z_xfRsZP","executionInfo":{"status":"ok","timestamp":1750098481865,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"be03df43-587c-46b9-edfd-47778a80f64d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9.0\n"]}]},{"cell_type":"code","source":["tk_tokenizer = tiktoken.get_encoding(\"gpt2\")"],"metadata":{"id":"7fOPAIzKOs5w","executionInfo":{"status":"ok","timestamp":1750098483802,"user_tz":-330,"elapsed":1935,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["text = \"Hello, I was checking out if there's any update. <|endoftext|> Mr. Rickham wanted to see it, she began, as if excusing herself.\"\n","encoded_text = tk_tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n","\n","print(encoded_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UF8xZNQRxwk","executionInfo":{"status":"ok","timestamp":1750098483849,"user_tz":-330,"elapsed":32,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"0435a065-b19a-4b3e-b2b9-0ea0eb63afae"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[15496, 11, 314, 373, 10627, 503, 611, 612, 338, 597, 4296, 13, 220, 50256, 1770, 13, 8759, 2763, 2227, 284, 766, 340, 11, 673, 2540, 11, 355, 611, 2859, 3500, 5223, 13]\n"]}]},{"cell_type":"code","source":["decoded_text = tk_tokenizer.decode(encoded_text)\n","\n","print(decoded_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ryhBqZfJc0H3","executionInfo":{"status":"ok","timestamp":1750098483882,"user_tz":-330,"elapsed":30,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"e994c6af-a605-43e5-ae8e-5164b5f24484"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, I was checking out if there's any update. <|endoftext|> Mr. Rickham wanted to see it, she began, as if excusing herself.\n"]}]},{"cell_type":"markdown","source":["Lets try BPE tokenizer on unknown word"],"metadata":{"id":"mjB-26uodhQr"}},{"cell_type":"code","source":["unknown_word = \"Akwirw ier\"\n","encoded_text = tk_tokenizer.encode(unknown_word)\n","print(encoded_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWea9CbUeHQ_","executionInfo":{"status":"ok","timestamp":1750098483964,"user_tz":-330,"elapsed":80,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"6e3e2d1a-bbcc-4dea-adae-d448b113cfae"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[33901, 86, 343, 86, 220, 959]\n"]}]},{"cell_type":"code","source":["#lets see how BPE breaks down the unknown word\n","for id in encoded_text:\n","  print(tk_tokenizer.decode([id]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Dfa-0U_ewP6","executionInfo":{"status":"ok","timestamp":1750098483965,"user_tz":-330,"elapsed":29,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"755c29b8-1101-4b9d-b990-0d9affb76547"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Ak\n","w\n","ir\n","w\n"," \n","ier\n"]}]},{"cell_type":"code","source":["#reconstruct the original token from token ids\n","print(tk_tokenizer.decode(encoded_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOHDVqvAfh1Y","executionInfo":{"status":"ok","timestamp":1750098483989,"user_tz":-330,"elapsed":28,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"6530e631-4d4a-4021-a666-e7c643793534"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Akwirw ier\n"]}]},{"cell_type":"markdown","source":["### Data Sampling"],"metadata":{"id":"gBQRG0KyC6vL"}},{"cell_type":"code","source":["#use Dataset and DataLoader classes from PyTorch for sampling\n","import torch\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"LfEqmEXTDAy0","executionInfo":{"status":"ok","timestamp":1750098493568,"user_tz":-330,"elapsed":9578,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["class GPTDataset(Dataset):\n","  def __init__(self, text, tokenizer, max_length, stride):\n","    self.inputs = []\n","    self.targets = []\n","\n","    encoded_text = tokenizer.encode(text)\n","\n","    for i in range(0,len(encoded_text) - max_length, stride):\n","      input = encoded_text[i:i+max_length]\n","      target = encoded_text[i+1:i+max_length+1]\n","\n","      self.inputs.append(torch.tensor(input))\n","      self.targets.append(torch.tensor(target))\n","\n","  def __len__(self):\n","    return len(self.inputs)\n","\n","  def __getitem__(self, index):\n","    return self.inputs[index], self.targets[index]"],"metadata":{"id":"WwsHwZlvKP7Y","executionInfo":{"status":"ok","timestamp":1750098493599,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def create_dataloader(text, batch_size=8, max_length=4, stride=4, drop_last=True, num_workers=0, shuffle=True):\n","  tokenizer = tiktoken.get_encoding('gpt2')\n","  dataset = GPTDataset(text,tokenizer, max_length, stride)\n","\n","  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n","\n","  return dataloader"],"metadata":{"id":"VXjgawUDOWs8","executionInfo":{"status":"ok","timestamp":1750098493605,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["dataloader = create_dataloader(raw_text, shuffle=False)"],"metadata":{"id":"Es3zeASLPdg1","executionInfo":{"status":"ok","timestamp":1750098493623,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["data_iter = iter(dataloader)\n","first_batch = next(data_iter)\n","print(first_batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUNXt5B4QWDn","executionInfo":{"status":"ok","timestamp":1750098493664,"user_tz":-330,"elapsed":38,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"6e2810a7-7a6a-4506-bde8-b5bdd10d3c06"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[   40,   367,  2885,  1464],\n","        [ 1807,  3619,   402,   271],\n","        [10899,  2138,   257,  7026],\n","        [15632,   438,  2016,   257],\n","        [  922,  5891,  1576,   438],\n","        [  568,   340,   373,   645],\n","        [ 1049,  5975,   284,   502],\n","        [  284,  3285,   326,    11]]), tensor([[  367,  2885,  1464,  1807],\n","        [ 3619,   402,   271, 10899],\n","        [ 2138,   257,  7026, 15632],\n","        [  438,  2016,   257,   922],\n","        [ 5891,  1576,   438,   568],\n","        [  340,   373,   645,  1049],\n","        [ 5975,   284,   502,   284],\n","        [ 3285,   326,    11,   287]])]\n"]}]},{"cell_type":"markdown","source":["### How to create Embeddings (or initial embeddings for LLM without word2vec)"],"metadata":{"id":"EUd-VtQjgGlo"}},{"cell_type":"code","source":["#lets consider a sample vocab of size 6\n","sample_vocab_size = 6\n","sample_vector_dim = 3\n","sample_token_ids = torch.tensor([5,3,1,4])"],"metadata":{"id":"dnEUT3VTgQb0","executionInfo":{"status":"ok","timestamp":1750098493707,"user_tz":-330,"elapsed":40,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#create a embedding layer with random initial weights\n","torch.manual_seed(123)\n","sample_embedding_layer = torch.nn.Embedding(sample_vocab_size, sample_vector_dim)\n","print(sample_embedding_layer.weight)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWkjq9Q7kpPA","executionInfo":{"status":"ok","timestamp":1750098672101,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"30895ca3-b230-41f4-913f-113c73606567"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[ 0.3374, -0.1778, -0.1690],\n","        [ 0.9178,  1.5810,  1.3010],\n","        [ 1.2753, -0.2010, -0.1606],\n","        [-0.4015,  0.9666, -1.1481],\n","        [-1.1589,  0.3255, -0.6315],\n","        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"]}]},{"cell_type":"code","source":["#convert token_ids to vectors\n","sample_vectors = sample_embedding_layer(sample_token_ids)\n","\n","print(sample_vectors)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNoIsC73l6dd","executionInfo":{"status":"ok","timestamp":1750098675134,"user_tz":-330,"elapsed":33,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"376b2c46-de74-4828-db97-7643a4612c9a"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-2.8400, -0.7849, -1.4096],\n","        [-0.4015,  0.9666, -1.1481],\n","        [ 0.9178,  1.5810,  1.3010],\n","        [-1.1589,  0.3255, -0.6315]], grad_fn=<EmbeddingBackward0>)\n"]}]},{"cell_type":"markdown","source":["#### Another way of implementing Embedding layer is using fully connected layer by one-hot encoding the token_id"],"metadata":{"id":"r6dix2S7mh-5"}},{"cell_type":"code","source":["#lets create a linear layer which replicates the embedding layer\n","linear = torch.nn.Linear(sample_vocab_size, sample_vector_dim, bias=False)\n","linear.weight = torch.nn.Parameter(sample_embedding_layer.weight.T) # copy weights of earlier embedding layer to this linear layer\n","\n","#before passing the token ids to the linear layer, lets first encode it using one-hot encoding\n","one_hot_encoded = torch.nn.functional.one_hot(sample_token_ids, num_classes=sample_vocab_size).float()\n","print(one_hot_encoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oasQdXdpm-ff","executionInfo":{"status":"ok","timestamp":1750098678506,"user_tz":-330,"elapsed":53,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"81e78ca9-bf2f-4c87-d935-891a2ed57db6"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 1., 0., 0.],\n","        [0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0.]])\n"]}]},{"cell_type":"code","source":["#lets use this one_hot_encoded ids to get embeddings\n","print(linear(one_hot_encoded))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bZFExZlqwYm","executionInfo":{"status":"ok","timestamp":1750098560610,"user_tz":-330,"elapsed":25,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"25141ef6-deca-4547-9ce4-2b7126056bc9"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-2.8400, -0.7849, -1.4096],\n","        [-0.4015,  0.9666, -1.1481],\n","        [ 0.9178,  1.5810,  1.3010],\n","        [-1.1589,  0.3255, -0.6315]], grad_fn=<MmBackward0>)\n"]}]},{"cell_type":"markdown","source":["As can be seen from both the outputs (embedding layer and linear), both the approaches results in same embeddings. The linear-one hot encoding approach is to demonstrate the underlying working of torch.nn.Embedding layer"],"metadata":{"id":"f7wFNLLVs7Ce"}},{"cell_type":"markdown","source":["### Creating Embeddings and encoding word positions for our dataset"],"metadata":{"id":"nCB-cmDPtbsi"}},{"cell_type":"code","source":["max_length = 4\n","vocab_size = 50257\n","vector_dim = 256\n","token_embedding_layer = torch.nn.Embedding(vocab_size, vector_dim)\n","pos_embedding_layer = torch.nn.Embedding(max_length, vector_dim)"],"metadata":{"id":"HXHZyag3CApX","executionInfo":{"status":"ok","timestamp":1750100271978,"user_tz":-330,"elapsed":133,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["inputs, targets = first_batch\n","token_embedding = token_embedding_layer(inputs)\n","pos_embedding = pos_embedding_layer(torch.arange(max_length))\n","\n","print(token_embedding.shape)\n","print(pos_embedding.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGMMQRm8_T_z","executionInfo":{"status":"ok","timestamp":1750100341505,"user_tz":-330,"elapsed":38,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"98041710-7839-407d-c4e2-b4532d3d9441"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 4, 256])\n","torch.Size([4, 256])\n"]}]},{"cell_type":"code","source":["input_embedding = token_embedding + pos_embedding\n","\n","print(input_embedding.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KeOHSnGGG3Uo","executionInfo":{"status":"ok","timestamp":1750100311824,"user_tz":-330,"elapsed":18,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"65cec278-893c-4ef8-9fd3-8b851149caab"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 4, 256])\n"]}]},{"cell_type":"code","source":["input_embedding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLAyyGy8IlM6","executionInfo":{"status":"ok","timestamp":1750100766438,"user_tz":-330,"elapsed":21,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"b03fb587-8ddf-4fbc-d79b-5e3494b55e28"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 9.7434e-01, -1.3013e+00, -2.5114e-01,  ...,  3.3158e-02,\n","          -1.9717e+00, -3.4217e-01],\n","         [-3.5572e-01, -1.2831e+00,  2.2670e+00,  ..., -1.3845e+00,\n","          -5.1235e-02, -8.2005e-01],\n","         [-2.1654e-01, -3.2127e+00,  1.6109e-01,  ...,  1.4438e+00,\n","           2.0039e+00, -1.4922e+00],\n","         [-1.0840e+00, -1.3802e+00,  1.1380e+00,  ..., -6.9833e-01,\n","           2.9245e+00, -1.2730e+00]],\n","\n","        [[-1.8876e-01,  9.7286e-01,  5.9313e-01,  ...,  1.6101e-01,\n","          -1.5308e+00, -4.1526e-01],\n","         [-1.6282e-02, -8.0122e-01, -2.1941e+00,  ..., -1.0970e+00,\n","           8.2290e-01, -3.1128e-01],\n","         [ 3.2220e-02, -1.6379e+00, -3.4350e-01,  ...,  7.3930e-01,\n","          -5.5135e-02, -1.0781e+00],\n","         [-2.4982e-01,  1.0538e+00,  6.3436e-01,  ..., -8.1458e-01,\n","           1.6490e+00, -1.7432e+00]],\n","\n","        [[ 1.2460e+00, -5.1565e-01, -3.4308e-01,  ..., -6.7881e-01,\n","          -2.0225e+00,  3.2037e+00],\n","         [ 2.3916e-01,  5.9045e-01, -1.7812e+00,  ..., -1.8126e+00,\n","          -1.1780e+00, -2.5637e-01],\n","         [-2.1922e+00, -3.7185e+00,  6.6194e-01,  ..., -9.2811e-01,\n","           1.0602e+00, -1.0320e+00],\n","         [ 4.8876e-01,  1.6275e-01,  2.9065e+00,  ..., -1.0686e+00,\n","           1.2047e+00, -1.1421e+00]],\n","\n","        ...,\n","\n","        [[ 1.7022e+00, -1.2862e+00,  4.9947e-01,  ...,  1.3241e+00,\n","          -1.1540e+00,  2.5218e+00],\n","         [-2.9333e-01, -1.2631e+00, -1.1909e+00,  ...,  1.4160e+00,\n","          -7.1849e-01, -5.8107e-01],\n","         [-3.4830e+00, -3.5161e+00, -1.6992e+00,  ..., -1.2403e+00,\n","           7.1576e-02, -1.1611e+00],\n","         [-2.2464e+00, -2.5560e-01,  4.5300e-01,  ...,  1.8275e+00,\n","           3.3008e-01,  8.4061e-03]],\n","\n","        [[ 1.1677e+00, -2.9699e-01, -2.1723e+00,  ...,  3.7972e-01,\n","          -1.3838e+00,  1.0102e+00],\n","         [ 6.3242e-01, -1.8338e-01, -3.7411e-01,  ..., -3.1488e-01,\n","          -1.5652e-01, -4.9920e-01],\n","         [-2.7547e+00, -1.2154e+00, -2.0087e+00,  ...,  1.3007e-01,\n","           5.5157e-01, -1.9710e-01],\n","         [-2.0873e+00,  8.1764e-01,  1.4451e+00,  ...,  1.2724e+00,\n","           7.8021e-01, -7.5328e-01]],\n","\n","        [[ 1.9680e-03,  3.0799e-01, -2.4079e+00,  ...,  2.7544e-02,\n","          -1.4532e+00,  2.2568e+00],\n","         [ 3.6763e-01, -2.1540e-01,  5.6448e-02,  ...,  1.4768e-01,\n","          -1.4903e+00,  1.1630e+00],\n","         [-2.5278e+00, -2.7097e+00, -8.5834e-01,  ..., -6.2591e-01,\n","           9.0588e-01, -2.1240e+00],\n","         [ 6.4247e-01, -7.5324e-01,  4.9031e-01,  ..., -8.1886e-01,\n","           2.2527e-01, -1.7022e+00]]], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":54}]}]}