{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1gMHi-RmWZSRBUmqWf2sQqOvuUV-6bPiw","authorship_tag":"ABX9TyMUUHBJHTW1Df16zWSnIIJd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5YVngyjDqUH9","executionInfo":{"status":"ok","timestamp":1752488070908,"user_tz":-330,"elapsed":4523,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import tiktoken as tk\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np"]},{"cell_type":"code","source":["GPT_CONFIG_124M = {\n","    'emb_size':768,\n","    'context_length':256,\n","    'vocab_size':50257,\n","    'num_heads':12,\n","    'num_layers':12,\n","    'drop_rate':0.1,\n","    'qkv_bias':False,\n","}"],"metadata":{"id":"CgDsvZznt4q9","executionInfo":{"status":"ok","timestamp":1752488070916,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## **Import GPT model and other building blocks**"],"metadata":{"id":"vQEPmaAXmR42"}},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, dim_in, dim_out, context_length, dropout, num_heads, qkv_bias=False):\n","    super().__init__()\n","    assert (dim_out % num_heads == 0), \"dim_out must be divisible by num_heads\"\n","\n","    self.dim_out = dim_out # final merged context vector embedding size\n","    self.num_heads = num_heads\n","    self.head_dim = dim_out//num_heads # embedding size of context vector in single head\n","    self.w_query = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.w_key = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.w_value = torch.nn.Linear(dim_in, dim_out, bias=qkv_bias)\n","    self.out_proj = torch.nn.Linear(dim_out, dim_out) # transform merged context_vectors into similar dimension size vectors\n","    self.dropout = torch.nn.Dropout(dropout)\n","    self.register_buffer(\n","        'mask',\n","        torch.triu(torch.ones(context_length, context_length), diagonal=1)\n","    )\n","\n","  def forward(self, x):\n","    batch_size, num_tokens, dim_in = x.shape\n","    queries = self.w_query(x)\n","    keys = self.w_key(x)\n","    values = self.w_value(x)  #shape (batch_size, num_tokens, dim_out)\n","\n","    queries = queries.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n","    keys = keys.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n","    values = values.view(batch_size, num_tokens, self.num_heads, self.head_dim) #shape (batch_size, num_tokens, num_heads, head_dim)\n","\n","    queries = queries.transpose(1,2)\n","    keys = keys.transpose(1,2)\n","    values = values.transpose(1,2) #shape (batch_size, num_heads, num_tokens, head_dim)\n","\n","    attention_scores = queries @ keys.transpose(2,3)\n","    attention_scores.masked_fill_(self.mask.bool()[:num_tokens,:num_tokens], -torch.inf)\n","\n","    attention_weights = torch.softmax(attention_scores/keys.shape[-1]**0.5, dim=-1)\n","    attention_weights = self.dropout(attention_weights)\n","\n","    context_vectors = (attention_weights @ values).transpose(1,2) #transposing axis 1,2  since we have to merge the context vectors by num_heads and head_dim, so required shape will now be (batch_size, num_tokens, num_heads, head_dim)\n","    context_vectors = context_vectors.contiguous().view(batch_size, num_tokens, self.dim_out)\n","\n","    context_vectors = self.out_proj(context_vectors)\n","\n","    return context_vectors"],"metadata":{"id":"X6ZTftNPt4tB","executionInfo":{"status":"ok","timestamp":1752488070921,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class LayerNorm(nn.Module):\n","  def __init__(self, emb_size):\n","    super().__init__()\n","    self.eps = 1e-5\n","    self.scale = nn.Parameter(torch.ones(emb_size))\n","    self.shift = nn.Parameter(torch.zeros(emb_size))\n","\n","  def forward(self, x):\n","    mean = x.mean(keepdim=True, dim=-1)\n","    variance = x.var(keepdim=True, dim=-1, unbiased=False)\n","    norm_x = (x - mean)/torch.sqrt(variance + self.eps)\n","    return self.scale * norm_x + self.shift"],"metadata":{"id":"eBDSxfUPlBQl","executionInfo":{"status":"ok","timestamp":1752488070925,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class GeLU(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","  def forward(self, x):\n","    return 0.5 * x * (1 + torch.tanh(\n","        torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x,3))\n","    ))"],"metadata":{"id":"ETrx3Wz8leW-","executionInfo":{"status":"ok","timestamp":1752488070929,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","  def __init__(self, cfg):\n","    super().__init__()\n","    self.layers = nn.Sequential(\n","        nn.Linear(cfg['emb_size'], 4 * cfg['emb_size']),\n","        GeLU(),\n","        nn.Linear(4 * cfg['emb_size'], cfg['emb_size'])\n","    )\n","\n","  def forward(self, x):\n","    return self.layers(x)"],"metadata":{"id":"55gMXA4tlere","executionInfo":{"status":"ok","timestamp":1752488070932,"user_tz":-330,"elapsed":1,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","  def __init__(self, cfg):\n","    super().__init__()\n","    self.mha = MultiHeadAttention(cfg['emb_size'], cfg['emb_size'], cfg['context_length'], cfg['drop_rate'], cfg['num_heads'], qkv_bias=cfg['qkv_bias'])\n","    self.layer_norm1 = LayerNorm(cfg['emb_size'])\n","    self.layer_norm2 = LayerNorm(cfg['emb_size'])\n","    self.ffn = FeedForward(cfg)\n","    self.dropout = nn.Dropout(cfg['drop_rate'])\n","\n","  def forward(self, x):\n","    shortcut = x\n","    x = self.layer_norm1(x)\n","    x = self.mha(x)\n","    x = self.dropout(x)\n","    x = x + shortcut\n","\n","    shortcut = x\n","    x = self.layer_norm2(x)\n","    x = self.ffn(x)\n","    x = self.dropout(x)\n","    x = x + shortcut\n","\n","    return x"],"metadata":{"id":"DirikFNtt4we","executionInfo":{"status":"ok","timestamp":1752488071003,"user_tz":-330,"elapsed":68,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class GPTModel(nn.Module):\n","  def __init__(self, cfg):\n","    super().__init__()\n","    self.token_emb_layer = nn.Embedding(cfg['vocab_size'], cfg['emb_size'])\n","    self.pos_emb_layer = nn.Embedding(cfg['context_length'], cfg['emb_size'])\n","    self.dropout_layer = nn.Dropout(cfg['drop_rate'])\n","    self.trf_blocks = nn.Sequential(\n","        *[TransformerBlock(cfg) for _ in range(cfg['num_layers'])]\n","    )\n","    self.final_norm = LayerNorm(cfg['emb_size'])\n","    self.output_layer = nn.Linear(cfg['emb_size'], cfg['vocab_size'], bias=False)\n","\n","  def forward(self, inp_tokens):\n","    batch_size, num_tokens = inp_tokens.shape\n","    token_emb = self.token_emb_layer(inp_tokens)\n","    pos_emb = self.pos_emb_layer(\n","        torch.arange(num_tokens, device=inp_tokens.device)\n","    )\n","    x = token_emb + pos_emb\n","    x = self.dropout_layer(x)\n","    x = self.trf_blocks(x)\n","    x = self.final_norm(x)\n","    logits = self.output_layer(x)\n","\n","    return logits"],"metadata":{"id":"wB6nFVnBlARI","executionInfo":{"status":"ok","timestamp":1752488071007,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def generate_text_tokens(model, inp_tokens, max_tokens, context_size):\n","  for _ in range(max_tokens):\n","    cropped_tokens = inp_tokens[:,-context_size:]\n","    with torch.no_grad():\n","      logits = model(cropped_tokens)\n","\n","    logits = logits[:,-1,:]\n","    prob = torch.softmax(logits, dim=-1)\n","    token_id = torch.argmax(prob, dim=-1, keepdim=True)\n","    inp_tokens = torch.cat((inp_tokens, token_id), dim=1)\n","\n","  return inp_tokens"],"metadata":{"id":"v3jwsP_nltVJ","executionInfo":{"status":"ok","timestamp":1752488071010,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## **Utility functions**"],"metadata":{"id":"1MD-QEkKmY4d"}},{"cell_type":"code","source":["def text_to_token_ids(text, tokenizer):\n","  encoded = tokenizer.encode(text)\n","  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n","  return encoded_tensor\n","\n","def token_ids_to_text(tokens, tokenizer):\n","  token_list = tokens.squeeze(0).tolist()\n","  decoded = tokenizer.decode(token_list)\n","  return decoded"],"metadata":{"id":"_-bcyg77mcAe","executionInfo":{"status":"ok","timestamp":1752488071013,"user_tz":-330,"elapsed":1,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## **Text Generation Loss**"],"metadata":{"id":"W9wnZaypbcej"}},{"cell_type":"code","source":["inp_text1 = \"every effort moves\"\n","inp_text2 = \"I really like\"\n","\n","target_text1 = \" effort moves you\"\n","target_text2 = \" really like chocolate\""],"metadata":{"id":"Bb2H1Uc2OMxk","executionInfo":{"status":"ok","timestamp":1752488071017,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer = tk.get_encoding(\"gpt2\")"],"metadata":{"id":"dSjO_kSt94Uz","executionInfo":{"status":"ok","timestamp":1752488072339,"user_tz":-330,"elapsed":1321,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["inp1 = text_to_token_ids(inp_text1, tokenizer)\n","inp2 = text_to_token_ids(inp_text2, tokenizer)\n","\n","target1 = text_to_token_ids(target_text1, tokenizer)\n","target2 = text_to_token_ids(target_text2, tokenizer)"],"metadata":{"id":"zvJUqUPEOQr3","executionInfo":{"status":"ok","timestamp":1752488072376,"user_tz":-330,"elapsed":35,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["target1, target2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxyFvvekENSX","executionInfo":{"status":"ok","timestamp":1752488072417,"user_tz":-330,"elapsed":38,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"009fec3f-be75-4cfe-9c8d-4d0c87f7c419"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[3626, 6100,  345]]), tensor([[ 1107,   588, 11311]]))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["inp = torch.cat((inp1, inp2), dim=0)\n","target = torch.cat((target1 , target2), dim=0)"],"metadata":{"id":"bs2gDCIj-PW0","executionInfo":{"status":"ok","timestamp":1752488072420,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","model = GPTModel(GPT_CONFIG_124M)\n","model.eval()\n","with torch.no_grad():\n","  pred = model(inp)\n","\n","print(pred.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"botNn6Gz-PiW","executionInfo":{"status":"ok","timestamp":1752488073863,"user_tz":-330,"elapsed":1441,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"90576231-4ba9-43b6-f79e-490da1080bbe"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3, 50257])\n"]}]},{"cell_type":"code","source":["probs = torch.softmax(pred, dim=-1)\n","probs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JEXFmXPIFLCC","executionInfo":{"status":"ok","timestamp":1752488073881,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"a2c1bc72-14a7-4318-880b-b11f0210e4d9"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3, 50257])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["max_tokens = torch.argmax(probs, dim=-1, keepdim=True)\n","output_tokens = max_tokens\n","print(output_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdSMA5GdFLEz","executionInfo":{"status":"ok","timestamp":1752488073889,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"5c911267-e1b7-4dde-fc0f-056aea32ea57"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[16657],\n","         [  339],\n","         [42826]],\n","\n","        [[49906],\n","         [29669],\n","         [41751]]])\n"]}]},{"cell_type":"code","source":["print(f'Original text: {token_ids_to_text(target[0], tokenizer)}')\n","print(f'Predicted text: {token_ids_to_text(output_tokens[0].squeeze(-1), tokenizer)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vztrkISaFLIF","executionInfo":{"status":"ok","timestamp":1752488073899,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"896cb944-d447-4c83-dd95-7171eb475d6f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Original text:  effort moves you\n","Predicted text:  Armed heNetflix\n"]}]},{"cell_type":"code","source":["#probability score of target token ids\n","batch_target_idx = 0\n","prob_text1 = probs[batch_target_idx, [0,1,2], target[batch_target_idx]]\n","\n","batch_target_idx = 1\n","prob_text2 = probs[batch_target_idx, [0,1,2], target[batch_target_idx]]\n","\n","print(prob_text1)\n","print(prob_text2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxOb78yFJpFm","executionInfo":{"status":"ok","timestamp":1752488073964,"user_tz":-330,"elapsed":64,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"750ea69c-994e-4023-cdae-3594a7e77050"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n","tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"]}]},{"cell_type":"code","source":["#LETS CALCULATE TEXT LOSS\n","##since we have already selected the probabilities of token indices\n","##first lets convert the probabilities to log probs and concatenate them\n","log_prob = torch.log(torch.cat((prob_text1, prob_text2), dim=-1))\n","\n","##lets take average now\n","avg_log_prob = torch.mean(log_prob)\n","\n","loss = avg_log_prob * -1\n","\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zB2_RsKRL5VI","executionInfo":{"status":"ok","timestamp":1752488073969,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"c6809a7a-90cc-4b4b-be10-bc83efe17f46"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(10.7940)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["#lets use cross_entropy funcntion to perform the above steps\n","pred_flat = torch.flatten(pred, 0, 1)\n","target_flat = torch.flatten(target)\n","\n","pred_flat.shape, target_flat.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_4E2o_LS_oK","executionInfo":{"status":"ok","timestamp":1752488073979,"user_tz":-330,"elapsed":10,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"88456416-e1e4-4974-a46c-410519a4de27"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([6, 50257]), torch.Size([6]))"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["cross_entropy_loss = torch.nn.functional.cross_entropy(pred_flat, target_flat)\n","cross_entropy_loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrBTgIE0cBaz","executionInfo":{"status":"ok","timestamp":1752488073986,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"a94f1368-4840-49ec-ce8c-7cf44265aa96"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(10.7940)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["#lets calculate perplexity\n","perplexity = torch.exp(cross_entropy_loss)\n","perplexity"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYqiwLzDcB3e","executionInfo":{"status":"ok","timestamp":1752488073996,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"60af4d5d-a08e-4837-f3c7-528d0be63860"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(48725.8203)"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## **Training and Validation set losses**"],"metadata":{"id":"LRYMWH7zda1Q"}},{"cell_type":"code","source":["class GPTDataset(Dataset):\n","  def __init__(self, text, tokenizer, max_length, stride):\n","    self.inputs = []\n","    self.targets = []\n","\n","    encoded_text = tokenizer.encode(text)\n","\n","    for i in range(0,len(encoded_text) - max_length, stride):\n","      input = encoded_text[i:i+max_length]\n","      target = encoded_text[i+1:i+max_length+1]\n","\n","      self.inputs.append(torch.tensor(input))\n","      self.targets.append(torch.tensor(target))\n","\n","  def __len__(self):\n","    return len(self.inputs)\n","\n","  def __getitem__(self, index):\n","    return self.inputs[index], self.targets[index]"],"metadata":{"id":"1Rjlc9J1dhSt","executionInfo":{"status":"ok","timestamp":1752488074000,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def create_dataloader(text, batch_size=8, max_length=4, stride=4, drop_last=True, num_workers=0, shuffle=True):\n","  tokenizer = tk.get_encoding('gpt2')\n","  dataset = GPTDataset(text,tokenizer, max_length, stride)\n","\n","  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n","\n","  return dataloader"],"metadata":{"id":"er7A6bIGdhVA","executionInfo":{"status":"ok","timestamp":1752488074003,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["file_path = \"/content/drive/My Drive/LLM/Data/the-verdict.txt\"\n","with open(file_path,\"r\",encoding=\"utf-8\") as f:\n","  raw_text = f.read()\n","\n","print(len(raw_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5Y419xUdhYW","executionInfo":{"status":"ok","timestamp":1752488075553,"user_tz":-330,"elapsed":1546,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"d2cc0b25-8381-4a1a-b4bf-cda14c1d115f"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["20479\n"]}]},{"cell_type":"code","source":["split_ratio = 0.9\n","train_text = raw_text[ : int(split_ratio * len(raw_text))]\n","val_text = raw_text[int(split_ratio * len(raw_text)) : ]"],"metadata":{"id":"7mjp1jIs_-o6","executionInfo":{"status":"ok","timestamp":1752488075565,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["train_loader = create_dataloader(train_text, batch_size=2, max_length=GPT_CONFIG_124M['context_length'], stride=GPT_CONFIG_124M['context_length'])\n","val_loader = create_dataloader(val_text, batch_size=2, max_length=GPT_CONFIG_124M['context_length'], stride=GPT_CONFIG_124M['context_length'])"],"metadata":{"id":"t4Gvflq6BGTO","executionInfo":{"status":"ok","timestamp":1752488075605,"user_tz":-330,"elapsed":38,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["for x,y in train_loader:\n","  print(x.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ESLOtirFPZs","executionInfo":{"status":"ok","timestamp":1752488075618,"user_tz":-330,"elapsed":11,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"932a876c-ed4d-48d1-b33c-4ff2161154dd"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n","torch.Size([2, 256]) torch.Size([2, 256])\n"]}]},{"cell_type":"code","source":["for x,y in val_loader:\n","  print(x.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1awXSWquFqIV","executionInfo":{"status":"ok","timestamp":1752488075627,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"83ee98ef-94a6-4e46-91c1-ad69d9461366"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 256]) torch.Size([2, 256])\n"]}]},{"cell_type":"code","source":["def ce_batch_loss_calc(input_batch, target_batch, model, device):\n","  \"\"\"\n","  ARGS\n","  input_batch: torch.tensor 2-D\n","  target_batch: torch.tensor 2-D\n","  model: GPTModel\n","  device: torch.device - 'cuda' or 'cpu'\n","\n","  calculates cross-entropy loss for a batch\n","  \"\"\"\n","  input_batch = input_batch.to(device)\n","  target_batch = target_batch.to(device)\n","  logits_batch = model(input_batch)\n","  loss = torch.nn.functional.cross_entropy(logits_batch.flatten(0, 1), target_batch.flatten())\n","\n","  return loss"],"metadata":{"id":"o7eBBDh8HyEY","executionInfo":{"status":"ok","timestamp":1752488075630,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def calc_loss_dataloader(loader, model, device, num_batches=None):\n","  \"\"\"\n","  ARGS\n","  loader: dataloader\n","  model: GPTModel\n","  device: torch.device - 'cuda' or 'cpu'\n","  num_batches: integer\n","\n","  calculates mean cross entropy loss across all the batches of the dataloader\n","  \"\"\"\n","  total_loss = 0\n","  if len(loader) == 0:\n","    return float('nan')\n","  elif num_batches is None:\n","    num_batches = len(loader)\n","  elif num_batches < 0:\n","    num_batches = float('nan')\n","  else:\n","    num_batches = min(num_batches, len(loader))\n","\n","  for i, (x, y) in enumerate(loader):\n","    if i < num_batches:\n","      loss = ce_batch_loss_calc(x, y, model, device)\n","      total_loss += loss\n","    else:\n","      break\n","\n","  return total_loss/num_batches"],"metadata":{"id":"AFroOi7gKqrt","executionInfo":{"status":"ok","timestamp":1752488075632,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6TPh8moQfEq","executionInfo":{"status":"ok","timestamp":1752488075666,"user_tz":-330,"elapsed":33,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"e6a1a9db-afce-4881-b13e-862c4e236e1a"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["model.to(device)\n","with torch.no_grad():\n","  train_loss = calc_loss_dataloader(train_loader, model=model, device = device)\n","  val_loss = calc_loss_dataloader(val_loader, model=model, device = device)\n","\n","print(f'Train loss: {train_loss}')\n","print(f'Validation loss: {val_loss}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTHRHEc4RBEW","executionInfo":{"status":"ok","timestamp":1752488077188,"user_tz":-330,"elapsed":1521,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"4a9d58a9-9c53-43f5-d128-d4e24dbfcf4e"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Train loss: 10.987584114074707\n","Validation loss: 10.981104850769043\n"]}]},{"cell_type":"markdown","source":["## **LLM Pretraining**"],"metadata":{"id":"nbMSj6V6bjvz"}},{"cell_type":"code","source":["def train_model_simple(model, train_loader, val_loader, device, optimizer, epochs, eval_freq, eval_iter, start_context, tokenizer):\n","  train_loss_arr, val_loss_arr, track_tokens_seen = [], [], []\n","  global_step, tokens_seen = -1, 0\n","\n","  for epoch in range(epochs):\n","    model.train()\n","    for x, y in train_loader:\n","      model.zero_grad()\n","      train_loss = ce_batch_loss_calc(x, y, model, device)\n","      train_loss.backward()\n","      optimizer.step()\n","      tokens_seen += x.numel()\n","      global_step += 1\n","\n","      if global_step % eval_freq == 0:\n","        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n","        train_loss_arr.append(train_loss)\n","        val_loss_arr.append(val_loss)\n","        track_tokens_seen.append(tokens_seen)\n","        print(f'Train loss after epoch {epoch} (Step: {global_step}): {train_loss:.3f}')\n","        print(f'Val loss after epoch {epoch} (Step: {global_step}): {val_loss:.3f}')\n","        print(f'Number of tokens seen after epoch {epoch} (Step: {global_step})')\n","\n","    generate_and_print_sample(model, start_context, tokenizer, device)\n","\n","  return train_loss_arr, val_loss_arr, track_tokens_seen"],"metadata":{"id":"tXb6jPt9bnt0","executionInfo":{"status":"ok","timestamp":1752488077191,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n","  model.eval()\n","  with torch.no_grad():\n","    train_loss = calc_loss_dataloader(train_loader, model, device, eval_iter)\n","    val_loss = calc_loss_dataloader(val_loader, model, device, eval_iter)\n","  model.train()\n","\n","  return train_loss, val_loss"],"metadata":{"id":"oltGxKXpb4Ft","executionInfo":{"status":"ok","timestamp":1752488077195,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def generate_and_print_sample(model, start_context, tokenizer, device):\n","  model.eval()\n","  context_size = model.trf_blocks[0].mha.mask.shape[0] ##model.pos_emb.shape[0]\n","  encoded_text = text_to_token_ids(start_context, tokenizer).to(device)\n","  with torch.no_grad():\n","    op_tokens = generate_text_tokens(model, encoded_text, max_tokens=50, context_size=context_size)\n","  decoded_text = token_ids_to_text(op_tokens, tokenizer)\n","\n","  print(decoded_text.replace('\\n',' '))\n","  model.train()"],"metadata":{"id":"lwYKXeDclmTE","executionInfo":{"status":"ok","timestamp":1752488077214,"user_tz":-330,"elapsed":18,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","model = GPTModel(GPT_CONFIG_124M)\n","model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n","train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, device, optimizer, epochs=10, eval_freq=5, eval_iter=5, start_context='Every effort moves you', tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sM9eXQi2rjPL","executionInfo":{"status":"ok","timestamp":1752488112283,"user_tz":-330,"elapsed":35066,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"0cc80e4b-950e-4d89-a03e-112009232a4a","collapsed":true},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Train loss after epoch 0 (Step: 0): 9.818\n","Val loss after epoch 0 (Step: 0): 9.930\n","Number of tokens seen after epoch 0 (Step: 0)\n","Train loss after epoch 0 (Step: 5): 7.920\n","Val loss after epoch 0 (Step: 5): 8.336\n","Number of tokens seen after epoch 0 (Step: 5)\n","Every effort moves you,,,,,,,,,,,,.                                     \n","Train loss after epoch 1 (Step: 10): 6.585\n","Val loss after epoch 1 (Step: 10): 7.046\n","Number of tokens seen after epoch 1 (Step: 10)\n","Train loss after epoch 1 (Step: 15): 5.984\n","Val loss after epoch 1 (Step: 15): 6.598\n","Number of tokens seen after epoch 1 (Step: 15)\n","Every effort moves you, the, and, the, the, the, and, the. \", the,,, the, and, the,, the,, the, and, the, the,, the, and,,,,, the\n","Train loss after epoch 2 (Step: 20): 15.871\n","Val loss after epoch 2 (Step: 20): 15.947\n","Number of tokens seen after epoch 2 (Step: 20)\n","Train loss after epoch 2 (Step: 25): 5.578\n","Val loss after epoch 2 (Step: 25): 6.453\n","Number of tokens seen after epoch 2 (Step: 25)\n","Every effort moves you. Gis. Gis. Gis. Gis. G. I had to----, and--. I had to--. I had. I had to the his--. I had the to the \", and I had.\n","Train loss after epoch 3 (Step: 30): 5.009\n","Val loss after epoch 3 (Step: 30): 6.335\n","Number of tokens seen after epoch 3 (Step: 30)\n","Train loss after epoch 3 (Step: 35): 4.767\n","Val loss after epoch 3 (Step: 35): 6.249\n","Number of tokens seen after epoch 3 (Step: 35)\n","Every effort moves you, and I had been the, I had to the picture. \", I had been--I, I had been the to the of the, I had the to the, I had been, I had the picture. \", I\n","Train loss after epoch 4 (Step: 40): 4.222\n","Val loss after epoch 4 (Step: 40): 6.236\n","Number of tokens seen after epoch 4 (Step: 40)\n","Every effort moves you know one of his pictures--I was his pictures--I was his last I felt to have to see it was not to have to see.                     \n","Train loss after epoch 5 (Step: 45): 3.578\n","Val loss after epoch 5 (Step: 45): 6.211\n","Number of tokens seen after epoch 5 (Step: 45)\n","Train loss after epoch 5 (Step: 50): 3.231\n","Val loss after epoch 5 (Step: 50): 6.189\n","Number of tokens seen after epoch 5 (Step: 50)\n","Every effort moves you know; and my a little of the picture--I had a little of a little: \"--I looked up, I had been to the donkey, I had a little at my dear, I had a little was his pictures--I was his\n","Train loss after epoch 6 (Step: 55): 2.823\n","Val loss after epoch 6 (Step: 55): 6.206\n","Number of tokens seen after epoch 6 (Step: 55)\n","Train loss after epoch 6 (Step: 60): 2.159\n","Val loss after epoch 6 (Step: 60): 6.181\n","Number of tokens seen after epoch 6 (Step: 60)\n","Every effort moves you know,\" was one of the picture for a smile that, I was one of the house.\"             He placed them at my elbow and I, the, and down the room, I was\n","Train loss after epoch 7 (Step: 65): 1.800\n","Val loss after epoch 7 (Step: 65): 6.180\n","Number of tokens seen after epoch 7 (Step: 65)\n","Train loss after epoch 7 (Step: 70): 1.393\n","Val loss after epoch 7 (Step: 70): 6.161\n","Number of tokens seen after epoch 7 (Step: 70)\n","Every effort moves you?\" \"I didn't you know after him, and Mrs.  \"I was no great, one of Jack's the man of the moment--as Jack himself, one might put it, I had a--because he had the picture\n","Train loss after epoch 8 (Step: 75): 1.165\n","Val loss after epoch 8 (Step: 75): 6.271\n","Number of tokens seen after epoch 8 (Step: 75)\n","Train loss after epoch 8 (Step: 80): 0.961\n","Val loss after epoch 8 (Step: 80): 6.323\n","Number of tokens seen after epoch 8 (Step: 80)\n","Every effort moves you?\" \"I that my hostess was \"interesting\": on that I was not till I can a year after Jack's resolve had been. \"--as Jack himself, as once one had longed to say: \"Be dissatisfied with your\n","Train loss after epoch 9 (Step: 85): 0.655\n","Val loss after epoch 9 (Step: 85): 6.364\n","Number of tokens seen after epoch 9 (Step: 85)\n","Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, the moment--as Jack himself, one might put it, had been the man of the hour. The\n"]}]},{"cell_type":"markdown","source":["## **Controlling LLM Output Randomness**"],"metadata":{"id":"xU4t4t3EXbGB"}},{"cell_type":"code","source":["vocab = {\n","    \"closer\":0,\n","    \"every\":1,\n","    \"effort\":2,\n","    \"forward\":3,\n","    \"inches\":4,\n","    \"moves\":5,\n","    \"pizza\":6,\n","    \"toward\":7,\n","    \"you\":8\n","}\n","\n","inverse_vocab = {v:k for k,v in vocab.items()}"],"metadata":{"id":"I4puRq7nXjhX","executionInfo":{"status":"ok","timestamp":1752488112288,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])"],"metadata":{"id":"u_dI-Q-bYUFl","executionInfo":{"status":"ok","timestamp":1752488112313,"user_tz":-330,"elapsed":23,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["#approach till now (using highest prob to select next token)\n","probs = torch.softmax(next_token_logits, dim=0)\n","next_token_id = torch.argmax(probs).item()\n","print(inverse_vocab[next_token_id])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6JS6NfKYhMi","executionInfo":{"status":"ok","timestamp":1752488112325,"user_tz":-330,"elapsed":10,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"b8c680c1-dcc0-4641-9be4-ba8d47948c96"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["forward\n"]}]},{"cell_type":"code","source":["#sampling from probability distribution using multinomial\n","torch.manual_seed(123)\n","next_token_id = torch.multinomial(probs, num_samples=1).item()\n","print(inverse_vocab[next_token_id])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmTeTLXeZpWl","executionInfo":{"status":"ok","timestamp":1752488112355,"user_tz":-330,"elapsed":28,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"bdf105a8-a1dc-4321-c452-51aea3bd33ca"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["toward\n"]}]},{"cell_type":"code","source":["sample_token_ids = [torch.multinomial(probs, num_samples=1) for _ in range(1000)]\n","counts = torch.bincount(torch.tensor(sample_token_ids))\n","for i, count in enumerate(counts):\n","  print(f'{inverse_vocab[i]}: {count}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2AHHmouUaX_Q","executionInfo":{"status":"ok","timestamp":1752488112363,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"3b86141d-4342-4f48-944e-e48d103e05c7"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["closer: 71\n","every: 2\n","effort: 0\n","forward: 544\n","inches: 2\n","moves: 1\n","pizza: 0\n","toward: 376\n","you: 4\n"]}]},{"cell_type":"markdown","source":["### Temperature Scaling"],"metadata":{"id":"ktFexqLSbiA_"}},{"cell_type":"code","source":["#scale logits by values greater than 0 before applying softmax to ajust the probability distribution\n","temperature = 2\n","scaled_logits = next_token_logits/temperature\n","softmax_probs = torch.softmax(scaled_logits, dim=0)\n","\n","sample_token_ids = [torch.multinomial(softmax_probs, num_samples=1) for _ in range(1000)]\n","counts = torch.bincount(torch.tensor(sample_token_ids))\n","for i, count in enumerate(counts):\n","  print(f'{inverse_vocab[i]}: {count}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_ckrh19blHd","executionInfo":{"status":"ok","timestamp":1752488112403,"user_tz":-330,"elapsed":38,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"f60e60f0-df34-4aa2-bf39-141400820492"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["closer: 142\n","every: 24\n","effort: 7\n","forward: 417\n","inches: 44\n","moves: 3\n","pizza: 2\n","toward: 325\n","you: 36\n"]}]},{"cell_type":"code","source":["#lets try higher temperature for more uniform distribution\n","temperature = 5\n","scaled_logits = next_token_logits/temperature\n","softmax_probs = torch.softmax(scaled_logits, dim=0)\n","\n","sample_token_ids = [torch.multinomial(softmax_probs, num_samples=1) for _ in range(1000)]\n","counts = torch.bincount(torch.tensor(sample_token_ids))\n","for i, count in enumerate(counts):\n","  print(f'{inverse_vocab[i]}: {count}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tkF5m2zsdR5z","executionInfo":{"status":"ok","timestamp":1752488112436,"user_tz":-330,"elapsed":36,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"a7b65667-7aa8-4da4-aae1-63275473569e"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["closer: 164\n","every: 87\n","effort: 52\n","forward: 245\n","inches: 85\n","moves: 44\n","pizza: 39\n","toward: 203\n","you: 81\n"]}]},{"cell_type":"code","source":["#lets try temperature lower than 1 for more sharper distribution\n","temperature = 0.2\n","scaled_logits = next_token_logits/temperature\n","softmax_probs = torch.softmax(scaled_logits, dim=0)\n","\n","sample_token_ids = [torch.multinomial(softmax_probs, num_samples=1) for _ in range(1000)]\n","counts = torch.bincount(torch.tensor(sample_token_ids))\n","for i, count in enumerate(counts):\n","  print(f'{inverse_vocab[i]}: {count}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJ5RF1hAdW1G","executionInfo":{"status":"ok","timestamp":1752488112457,"user_tz":-330,"elapsed":24,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"193ed731-2b41-4c06-b9f6-92afe24b1b30"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["closer: 0\n","every: 0\n","effort: 0\n","forward: 927\n","inches: 0\n","moves: 0\n","pizza: 0\n","toward: 73\n"]}]},{"cell_type":"code","source":["def softmax_with_temperature(logits, temperature):\n","  scaled_logits = logits/temperature\n","  scaled_probs = torch.softmax(scaled_logits, dim=0)\n","  return scaled_probs"],"metadata":{"id":"v6nhub6kd7uP","executionInfo":{"status":"ok","timestamp":1752488112471,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["#lets visualize this using bar chart for different temperatures\n","import matplotlib.pyplot as plt\n","temperatures = [0.2, 1, 5]\n","scaled_probs = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n","x = torch.arange(len(vocab))\n","bar_width = 0.15\n","fig, ax = plt.subplots(figsize=(5,3))\n","for i, T in enumerate(temperatures):\n","  rects = ax.bar(x + i * bar_width, scaled_probs[i], bar_width, label=f'Temperature = {T}')\n","ax.set_ylabel('Probability')\n","ax.set_xticks(x)\n","ax.set_xticklabels(vocab.keys(), rotation=90)\n","ax.legend()\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"PEViaB1ndyw5","executionInfo":{"status":"ok","timestamp":1752488112867,"user_tz":-330,"elapsed":394,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"5f3336c2-49e2-4072-cf1f-75758f4a7c90"},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 500x300 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### Top-k sampling"],"metadata":{"id":"rtztGLBntubb"}},{"cell_type":"code","source":["top_k=3\n","top_logits, top_idx = torch.topk(next_token_logits, top_k)\n","print(top_logits)\n","print(top_idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVCR-iT-twzK","executionInfo":{"status":"ok","timestamp":1752488112868,"user_tz":-330,"elapsed":39,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"26581a04-886a-40c1-c02c-98e81fbe9b25"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([6.7500, 6.2800, 4.5100])\n","tensor([3, 7, 0])\n"]}]},{"cell_type":"code","source":["masked_logits = torch.where(\n","    condition = next_token_logits < top_logits[-1],\n","    input = torch.tensor(float('-inf')),\n","    other = next_token_logits\n",")\n","\n","masked_logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCcwJedbzUte","executionInfo":{"status":"ok","timestamp":1752488112868,"user_tz":-330,"elapsed":31,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"569d080d-babb-41d9-e219-057f58940b30"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["top_k_softmax_probs = torch.softmax(masked_logits, dim=0)\n","top_k_softmax_probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HstiBn8c10sF","executionInfo":{"status":"ok","timestamp":1752488112868,"user_tz":-330,"elapsed":25,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"34eb7ae4-ae03-4949-ba28-d18acb3edda1"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["### Generate fn"],"metadata":{"id":"bl72-dnM5cTA"}},{"cell_type":"code","source":["def generate(model, inp_tokens, context_size, max_tokens, temperature=0.0, top_k=None, eos_id=None):\n","  for i in range(max_tokens):\n","    cond_inp = inp_tokens[:,-context_size:]\n","    with torch.no_grad():\n","      logits = model(cond_inp)\n","    logits = logits[:,-1,:]\n","\n","    if top_k is not None:\n","      top_logits, top_idx = torch.topk(logits, top_k)\n","      logits = torch.where(\n","          condition=logits<top_logits[:,-1],\n","          input=torch.tensor(float('-inf')),\n","          other=logits\n","      )\n","\n","    if temperature > 0:\n","      scaled_logits = logits / temperature\n","      probs = torch.softmax(scaled_logits, dim=-1)\n","      idx_next = torch.multinomial(probs, num_samples=1)\n","    else:\n","      idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n","\n","    if idx_next == eos_id:\n","      break\n","\n","    inp_tokens = torch.cat((inp_tokens, idx_next), dim=1)\n","\n","  return inp_tokens"],"metadata":{"id":"Fh0Z9us65ezI","executionInfo":{"status":"ok","timestamp":1752488112869,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(123)\n","model.to('cpu')\n","model.eval()\n","output_tokens = generate(\n","    model,\n","    inp_tokens=text_to_token_ids(\"Every effort moves you\", tokenizer),\n","    context_size=GPT_CONFIG_124M['context_length'],\n","    max_tokens=15,\n","    temperature=1.4,\n","    top_k=25\n",")\n","\n","print(token_ids_to_text(output_tokens, tokenizer))"],"metadata":{"id":"93psvTc3998N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752488115219,"user_tz":-330,"elapsed":2355,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"c4c28480-21a4-44dc-e6ad-02dea9f616c5"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Every effort moves you know began to happen a hint of--I looked on my dear; and\n"]}]},{"cell_type":"markdown","source":["## **Saving and Loading Model Weights**"],"metadata":{"id":"b0iLK-b8V2Cl"}},{"cell_type":"code","source":["### saving and loading only model\n","\"\"\"\n","torch.save(model.state_dict(), \"/content/drive/My Drive/LLM/Data/model.pth\")\n","model = GPTModel(GPT_CONFIG_124M)\n","checkpoint = torch.load(\"model.pth\", map_location=device)\n","model.load_state_dict(checkpoint)\n","\"\"\""],"metadata":{"id":"RsoMQE0bV0Xg","executionInfo":{"status":"ok","timestamp":1752488115225,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"06e75ffa-e3b7-4e19-924f-204555a86010"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntorch.save(model.state_dict(), \"/content/drive/My Drive/LLM/Data/model.pth\")\\nmodel = GPTModel(GPT_CONFIG_124M)\\ncheckpoint = torch.load(\"model.pth\", map_location=device)\\nmodel.load_state_dict(checkpoint)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["### saving model and optimizer\n","torch.save({\n","    \"model_state_dict\": model.state_dict(),\n","    \"optimizer_state_dict\": optimizer.state_dict()\n","}, \"/content/drive/My Drive/LLM/Data/model_and_optimizer.pth\")"],"metadata":{"id":"J-1NCDJ8YW1q","executionInfo":{"status":"ok","timestamp":1752489202387,"user_tz":-330,"elapsed":12718,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["#loading model ad optimizer parameters\n","checkpoint = torch.load(\"/content/drive/My Drive/LLM/Data/model_and_optimizer.pth\", map_location=device)\n","model = GPTModel(GPT_CONFIG_124M)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","model.train()"],"metadata":{"id":"agM-Wa15YwYn","executionInfo":{"status":"ok","timestamp":1752488130373,"user_tz":-330,"elapsed":4973,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"outputId":"273180b4-dce5-46ba-db37-d2d96055e2cf"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (token_emb_layer): Embedding(50257, 768)\n","  (pos_emb_layer): Embedding(256, 768)\n","  (dropout_layer): Dropout(p=0.1, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=False)\n","        (w_key): Linear(in_features=768, out_features=768, bias=False)\n","        (w_value): Linear(in_features=768, out_features=768, bias=False)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (output_layer): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["## **Loading OpenAI Pretrained Weights**"],"metadata":{"id":"TogM-ZUXTxmu"}},{"cell_type":"code","source":["import urllib.request\n","url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\"\n","filename = f\"/content/drive/My Drive/LLM/Notebooks/{url.split('/')[-1]}\"\n","urllib.request.urlretrieve(url, filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGrdJiH6T2N8","executionInfo":{"status":"ok","timestamp":1752488130848,"user_tz":-330,"elapsed":475,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"4d207e61-ef2d-4f99-c3e3-d27c7dc7f30e"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/LLM/Notebooks/gpt_download.py',\n"," <http.client.HTTPMessage at 0x7e4e0e37f410>)"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/My Drive/LLM/Notebooks')"],"metadata":{"id":"6XX_YWyLWcV1","executionInfo":{"status":"ok","timestamp":1752488130852,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["from gpt_download import download_and_load_gpt2\n","settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir='gpt2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyK8fGwuXQcJ","executionInfo":{"status":"ok","timestamp":1752488186197,"user_tz":-330,"elapsed":55346,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"fbbda7e1-1402-4e93-c3c9-c35fa8d05161"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stderr","text":["checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 103kiB/s]\n","encoder.json: 100%|| 1.04M/1.04M [00:00<00:00, 1.96MiB/s]\n","hparams.json: 100%|| 90.0/90.0 [00:00<00:00, 125kiB/s]\n","model.ckpt.data-00000-of-00001: 100%|| 498M/498M [00:46<00:00, 10.6MiB/s]\n","model.ckpt.index: 100%|| 5.21k/5.21k [00:00<00:00, 6.56MiB/s]\n","model.ckpt.meta: 100%|| 471k/471k [00:00<00:00, 1.63MiB/s]\n","vocab.bpe: 100%|| 456k/456k [00:00<00:00, 1.58MiB/s]\n"]}]},{"cell_type":"code","source":["print(f'Settings: {settings}')\n","print(f'Params dict keys: {params.keys()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ve7Whv8TX--i","executionInfo":{"status":"ok","timestamp":1752488186208,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"7b90ffc2-ea5a-4af2-86f4-7e24d6fe44e9"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n","Params dict keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"]}]},{"cell_type":"code","source":["print(params['wte'])\n","print(f\"Shape: {params['wte'].shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"na4FqQNUYN9g","executionInfo":{"status":"ok","timestamp":1752488186217,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"09bdeb4b-34b7-4a1d-ba18-ba1bb4c086f7"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n","   0.04531523]\n"," [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n","   0.04318958]\n"," [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n","  -0.08785918]\n"," ...\n"," [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n","  -0.06952604]\n"," [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n","  -0.02245961]\n"," [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n","   0.12067825]]\n","Shape: (50257, 768)\n"]}]},{"cell_type":"code","source":["model_configs = {\n","    'gpt2-small (124M)': {\n","        'emb_size':768,\n","        'num_heads':12,\n","        'num_layers':12,\n","    },\n","    'gpt2-medium (355M)': {\n","        'emb_size':1024,\n","        'num_heads':16,\n","        'num_layers':24,\n","    },\n","    'gpt2-large (774M)': {\n","        'emb_size':1280,\n","        'num_heads':20,\n","        'num_layers':36,\n","    },\n","    'gpt2-xl (1558M)': {\n","        'emb_size':1600,\n","        'num_heads':25,\n","        'num_layers':48,\n","    }\n","}"],"metadata":{"id":"9fuWKBC5YnN3","executionInfo":{"status":"ok","timestamp":1752488186218,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["model_name = 'gpt2-small (124M)'\n","NEW_CONFIG = GPT_CONFIG_124M.copy()\n","NEW_CONFIG.update(model_configs[model_name])\n","\n","NEW_CONFIG.update({'context_length':1024})\n","NEW_CONFIG.update({'qkv_bias': True})"],"metadata":{"id":"j-BaJ9hCZpVv","executionInfo":{"status":"ok","timestamp":1752488186272,"user_tz":-330,"elapsed":52,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["print(NEW_CONFIG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYcfCoNeah2i","executionInfo":{"status":"ok","timestamp":1752488186273,"user_tz":-330,"elapsed":36,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"32d6e54a-5dbe-4e9b-8010-005a5a922b22"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["{'emb_size': 768, 'context_length': 1024, 'vocab_size': 50257, 'num_heads': 12, 'num_layers': 12, 'drop_rate': 0.1, 'qkv_bias': True}\n"]}]},{"cell_type":"code","source":["gpt = GPTModel(NEW_CONFIG)\n","gpt.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ef4FKOfebBNS","executionInfo":{"status":"ok","timestamp":1752488187569,"user_tz":-330,"elapsed":1299,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"84b7c8d3-22b9-4853-e8a5-3440367735d1"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (token_emb_layer): Embedding(50257, 768)\n","  (pos_emb_layer): Embedding(1024, 768)\n","  (dropout_layer): Dropout(p=0.1, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (output_layer): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["def assign(left, right):\n","  if left.shape != right.shape:\n","    raise ValueError(f'Shape mismatch. Left: {left.shape}. Right: {right.shape}')\n","  return torch.nn.Parameter(torch.tensor(right))"],"metadata":{"id":"jnV79_FscO8B","executionInfo":{"status":"ok","timestamp":1752488187574,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["def load_parameters(gpt, params):\n","  gpt.token_emb_layer.weight = assign(gpt.token_emb_layer.weight, params['wte'])\n","  gpt.pos_emb_layer.weight = assign(gpt.pos_emb_layer.weight, params['wpe'])\n","\n","  #transformer blocks' parameters loading\n","  for b in range(len(params['blocks'])):\n","    #each blocks' mha qkv weights\n","    q_w, k_w, v_w = np.split(\n","        params['blocks'][b]['attn']['c_attn']['w'], 3, axis=-1\n","    )\n","    gpt.trf_blocks[b].mha.w_query.weight = assign(\n","        gpt.trf_blocks[b].mha.w_query.weight, q_w.T\n","    )\n","    gpt.trf_blocks[b].mha.w_key.weight = assign(\n","        gpt.trf_blocks[b].mha.w_key.weight, k_w.T\n","    )\n","    gpt.trf_blocks[b].mha.w_value.weight = assign(\n","        gpt.trf_blocks[b].mha.w_value.weight, v_w.T\n","    )\n","\n","    #each blocks' mha qkv bias\n","    q_b, k_b, v_b = np.split(\n","        params['blocks'][b]['attn']['c_attn']['b'], 3, axis=-1\n","    )\n","    gpt.trf_blocks[b].mha.w_query.bias = assign(\n","        gpt.trf_blocks[b].mha.w_query.bias, q_b\n","    )\n","    gpt.trf_blocks[b].mha.w_key.bias = assign(\n","        gpt.trf_blocks[b].mha.w_key.bias, k_b\n","    )\n","    gpt.trf_blocks[b].mha.w_value.bias = assign(\n","        gpt.trf_blocks[b].mha.w_value.bias, v_b\n","    )\n","\n","    #each blocks' mha out_proj layer's weight and bias\n","    gpt.trf_blocks[b].mha.out_proj.weight = assign(\n","        gpt.trf_blocks[b].mha.out_proj.weight, params['blocks'][b]['attn']['c_proj']['w'].T\n","    )\n","    gpt.trf_blocks[b].mha.out_proj.bias = assign(\n","        gpt.trf_blocks[b].mha.out_proj.bias, params['blocks'][b]['attn']['c_proj']['b']\n","    )\n","\n","    #each blocks' ff wieghts and biases\n","    gpt.trf_blocks[b].ffn.layers[0].weight = assign(\n","        gpt.trf_blocks[b].ffn.layers[0].weight, params['blocks'][b]['mlp']['c_fc']['w'].T\n","    )\n","    gpt.trf_blocks[b].ffn.layers[0].bias = assign(\n","        gpt.trf_blocks[b].ffn.layers[0].bias, params['blocks'][b]['mlp']['c_fc']['b']\n","    )\n","    gpt.trf_blocks[b].ffn.layers[2].weight = assign(\n","        gpt.trf_blocks[b].ffn.layers[2].weight, params['blocks'][b]['mlp']['c_proj']['w'].T\n","    )\n","    gpt.trf_blocks[b].ffn.layers[2].bias = assign(\n","        gpt.trf_blocks[b].ffn.layers[2].bias, params['blocks'][b]['mlp']['c_proj']['b']\n","    )\n","\n","    #each blocks' layer_norms scale and shift\n","    gpt.trf_blocks[b].layer_norm1.scale = assign(\n","        gpt.trf_blocks[b].layer_norm1.scale, params['blocks'][b]['ln_1']['g']\n","    )\n","    gpt.trf_blocks[b].layer_norm1.shift = assign(\n","        gpt.trf_blocks[b].layer_norm1.shift, params['blocks'][b]['ln_1']['b']\n","    )\n","    gpt.trf_blocks[b].layer_norm2.scale = assign(\n","        gpt.trf_blocks[b].layer_norm2.scale, params['blocks'][b]['ln_2']['g']\n","    )\n","    gpt.trf_blocks[b].layer_norm2.shift = assign(\n","        gpt.trf_blocks[b].layer_norm2.shift, params['blocks'][b]['ln_2']['b']\n","    )\n","\n","  #gpt's final_layer_norm\n","  gpt.final_norm.scale = assign(\n","        gpt.final_norm.scale, params['g']\n","  )\n","  gpt.final_norm.shift = assign(\n","        gpt.final_norm.shift, params['b']\n","  )\n","  gpt.output_layer.weight = assign(\n","      gpt.output_layer.weight, params['wte']\n","  )"],"metadata":{"id":"WkBuC8Ahf5bB","executionInfo":{"status":"ok","timestamp":1752488187586,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["load_parameters(gpt, params)\n","gpt.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"OMXNAVgapN78","executionInfo":{"status":"ok","timestamp":1752488188102,"user_tz":-330,"elapsed":514,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"e148060b-5db1-4813-8a42-3b5f6c48de02"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPTModel(\n","  (token_emb_layer): Embedding(50257, 768)\n","  (pos_emb_layer): Embedding(1024, 768)\n","  (dropout_layer): Dropout(p=0.1, inplace=False)\n","  (trf_blocks): Sequential(\n","    (0): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (1): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (2): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (3): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (4): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (5): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (6): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (7): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (8): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (9): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (10): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (11): TransformerBlock(\n","      (mha): MultiHeadAttention(\n","        (w_query): Linear(in_features=768, out_features=768, bias=True)\n","        (w_key): Linear(in_features=768, out_features=768, bias=True)\n","        (w_value): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (layer_norm1): LayerNorm()\n","      (layer_norm2): LayerNorm()\n","      (ffn): FeedForward(\n","        (layers): Sequential(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GeLU()\n","          (2): Linear(in_features=3072, out_features=768, bias=True)\n","        )\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_norm): LayerNorm()\n","  (output_layer): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["torch.manual_seed(123)\n","output = generate(\n","    gpt,\n","    text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n","    NEW_CONFIG['context_length'],\n","    25,\n","    1.5,\n","    50\n",")\n","\n","print(token_ids_to_text(output, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54HCPcaFrk1o","executionInfo":{"status":"ok","timestamp":1752488791573,"user_tz":-330,"elapsed":697,"user":{"displayName":"Shrut Dalwadi","userId":"08414839699938435262"}},"outputId":"7d25a965-dd72-46cf-d36c-07046d513b6f"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["Every effort moves you as far as the hand can go until the end of your turn unless something happens\n","\n","This would remove you from a battle\n"]}]}]}